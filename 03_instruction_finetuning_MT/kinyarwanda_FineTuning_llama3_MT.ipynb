{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3179316",
   "metadata": {},
   "source": [
    "## Instruction fine-tuning Kinyarwanda \n",
    "\n",
    "\n",
    "this is an experimental notebook to fine-tune llama 3 for Kinyarwanda \n",
    "\n",
    "in this notebook we fine-tune for machine translation \n",
    "\n",
    "\n",
    "we use \n",
    "- llama3-8b model that which was \"continue-pretrained\" on Kinyarwanda \n",
    "- Unsloth as a fine-tuning framework \n",
    "- datasets: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664f907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import json \n",
    "import pandas as pd \n",
    "\n",
    "import random \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44e2cc89",
   "metadata": {},
   "source": [
    "## 1 . loading the model & fine-tuning parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c7f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Llama patching release 2024.6\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.647 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Unsloth 2024.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# we use unsloth & here we load the model \n",
    "\n",
    "max_seq_length = 2048 # this can be adapted for longer context \n",
    "dtype = None # the datatype will be auto-detected : Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # we use 4bit quantization to reduce memory usage. \n",
    "\n",
    "# pre-trained model \n",
    "\n",
    "xmodel = '/home/mike/xGitHubRepos/kinyarwanda_ft_llm/02_continue_pretraining/llamarwanda_rw_v002'\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = xmodel , \n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089199ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Casting embed_tokens to float32\n",
      "Unsloth: Casting lm_head to float32\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\",\n",
    "                      \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"], \n",
    "                      # we exclude \"embed_tokens\", \"lm_head\",] used for continual pretraining\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443557e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb2506ec",
   "metadata": {},
   "source": [
    "## 2 . loading the datasets \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e708b9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47824\n"
     ]
    }
   ],
   "source": [
    "xlst_all = []\n",
    "\n",
    "xfile_name = '/home/mike/xTemp_data_infrastructure/_kinyarwanda_datasets/kinyarwanda_MT.jsonl'\n",
    "\n",
    "with open(xfile_name, 'r') as file:\n",
    "    for line in file:\n",
    "        xjson = json.loads(line)\n",
    "        xlst_all.append( xjson )\n",
    "        \n",
    "print(len(xlst_all))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4d6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(xlist):\n",
    "    '''\n",
    "    split list in two equal parts \n",
    "    '''\n",
    "    xhalf = int(len(xlist)/2)\n",
    "    xlst_a = xlist[0:xhalf]\n",
    "    xlst_b = xlist[0:xhalf]    \n",
    "    return xlst_a, xlst_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78f133af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47812 2812 45000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1406, 1406, 22500, 22500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# shuffle list \n",
    "xlst_all = random.sample(xlst_all, len(xlst_all))\n",
    "       \n",
    "# we filter some strange cases \n",
    "xlst_all = [x for x in xlst_all if isinstance(x.get('kin'), str) ]\n",
    "xlst_all = [x for x in xlst_all if isinstance(x.get('en'), str) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "##splt the list in train and test \n",
    "\n",
    "xtest = xlst_all[0:2812]\n",
    "xtrain = xlst_all[2812:]    \n",
    "    \n",
    "print(len(xlst_all), len(xtest), len(xtrain))\n",
    "\n",
    "#create splits to use for kin->en and en-kin \n",
    "\n",
    "xtest_a, xtest_b = split_list(xtest )\n",
    "xtrain_a, xtrain_b = split_list(xtrain )\n",
    "len(xtest_a), len(xtest_b), len(xtrain_a), len(xtrain_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b877885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "736f20b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "translate the following text from kinyarwanda to english<|im_end|>\n",
      "<|im_start|>user\n",
      "Niba ubwiye mwarimu wawe ko wabuze umukoro wawe, ntabwo azakwemera.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "If you tell your teacher that you have lost your homework, he or she will not accept you.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|im_start|>user\n",
      "translate the following text from english to kinyarwanda<|im_end|>\n",
      "<|im_start|>user\n",
      "If you tell your teacher that you have lost your homework, he or she will not accept you.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Niba ubwiye mwarimu wawe ko wabuze umukoro wawe, ntabwo azakwemera.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def translate_kin_en(xtext):\n",
    "    '''\n",
    "    apply template to kin_en \n",
    "    '''\n",
    "    x1 = 'translate the following text from kinyarwanda to english'\n",
    "    messages=[{ 'role': 'user', 'content': x1},\n",
    "              { 'role': 'user', 'content': xtext.get('kin') },\n",
    "              { 'role': 'assistant', 'content': xtext.get('en')}] \n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return inputs\n",
    "    \n",
    "def translate_en_kin(xtext):\n",
    "    '''\n",
    "    apply template to kin_en \n",
    "    '''\n",
    "    x1 = 'translate the following text from english to kinyarwanda'\n",
    "\n",
    "    messages=[{ 'role': 'user', 'content': x1},\n",
    "              { 'role': 'user', 'content': xtext.get('en') },\n",
    "              { 'role': 'assistant', 'content': xtext.get('kin')}] \n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\n",
    "xtext = random.sample(xtest_a,1)[0]    \n",
    "    \n",
    "print(translate_kin_en(xtext))\n",
    "print(translate_en_kin(xtext))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52dacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd573ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c653efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "234fd55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 100\n",
       " }))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsttext_train = []\n",
    "lsttext_test  = []\n",
    "\n",
    "for xtext in  xtrain_a:\n",
    "    xdict = {}\n",
    "    xdict['text'] =  translate_kin_en(xtext)\n",
    "    lsttext_train.append(xdict)\n",
    "for xtext in  xtrain_b:\n",
    "    xdict = {}\n",
    "    xdict['text'] =  translate_en_kin(xtext)\n",
    "    lsttext_train.append(xdict)\n",
    "    \n",
    "for xtext in  xtest_a:\n",
    "    xdict = {}\n",
    "    xdict['text'] =  translate_kin_en(xtext)\n",
    "    lsttext_test.append(xdict)    \n",
    "    \n",
    "for xtext in  xtest_b:\n",
    "    xdict = {}\n",
    "    xdict['text'] =  translate_en_kin(xtext)\n",
    "    lsttext_test.append(xdict)        \n",
    "    \n",
    "\n",
    "#to test \n",
    "lsttext_train = lsttext_train[0:1000]\n",
    "lsttext_test = lsttext_test[0:100]\n",
    "    \n",
    "    \n",
    "dataset_train = Dataset.from_pandas(pd.DataFrame(lsttext_train))\n",
    "dataset_test  = Dataset.from_pandas(pd.DataFrame(lsttext_test))\n",
    "\n",
    "\n",
    "dataset_train = dataset_train.shuffle(seed=42)\n",
    "dataset_test = dataset_test.shuffle(seed=42)\n",
    "\n",
    "dataset_train, dataset_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12d9be6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<|im_start|>user\\ntranslate the following text from kinyarwanda to english<|im_end|>\\n<|im_start|>user\\nMu icupa hari amazi make. <|im_end|>\\n<|im_start|>assistant\\nThere is little water in the bottle.<|im_end|>\\n<|im_start|>assistant\\n'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306edf9",
   "metadata": {},
   "source": [
    "## 3  Training arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9535f4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24497dcd12944b1e860b41b7093429f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff52b55d70141bbb0f13035ffe061de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset_train,\n",
    "    eval_dataset = dataset_test,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "\n",
    "        # Use warmup_ratio and num_train_epochs for longer runs!\n",
    "        #max_steps = 120,\n",
    "        #warmup_steps = 10,\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 2, \n",
    "\n",
    "        # Select a 2 to 10x smaller learning rate for the embedding matrices!\n",
    "        learning_rate = 5e-5,\n",
    "        embedding_learning_rate = 1e-5,\n",
    "\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5769c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4090. Max memory = 23.647 GB.\n",
      "13.82 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fccd5c",
   "metadata": {},
   "source": [
    "## train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6de9287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 16 | Total steps = 124\n",
      " \"-____-\"     Number of trainable parameters = 335,544,320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 03:21, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.613400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.857800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.826600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.838900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.648300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.641500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.671200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.638900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.596200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.600500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.559600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.563900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.572200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.581100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.614900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.641500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.592600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.759900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.638200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.586900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.398100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.298200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.390500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.352300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.333100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.279200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.405900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.330700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.338900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.334600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.333600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.316300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe52cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204.3434 seconds used for training.\n",
      "3.41 minutes used for training.\n",
      "Peak reserved memory = 13.82 GB.\n",
      "Peak reserved memory for training = 0.0 GB.\n",
      "Peak reserved memory % of max memory = 58.443 %.\n",
      "Peak reserved memory for training % of max memory = 0.0 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840776c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7cfa3b",
   "metadata": {},
   "source": [
    "# inference \n",
    "\n",
    "\n",
    "### THIS IS TESTS FROM THE ABOVE SETTINGS WE USE ONLY 1000 examples, the training takes about 4 minutes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2dcbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44072c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb785b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c21fb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_translate_kin_en(xtext):\n",
    "    '''\n",
    "    apply template to kin_en \n",
    "    '''\n",
    "    x1 = 'translate the following text from kinyarwanda to english'\n",
    "    messages=[{ 'role': 'user', 'content': x1},\n",
    "              { 'role': 'user', 'content': xtext }] \n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return inputs\n",
    "    \n",
    "def eval_translate_en_kin(xtext):\n",
    "    '''\n",
    "    apply template to kin_en \n",
    "    '''\n",
    "    x1 = 'translate the following text from english to kinyarwanda'\n",
    "\n",
    "    messages=[{ 'role': 'user', 'content': x1},\n",
    "              { 'role': 'user', 'content': xtext }]\n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a39f958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_kin_en(xtext):\n",
    "    '''\n",
    "    translate from Kinyarwanda to english \n",
    "    '''\n",
    "    \n",
    "    #apply template \n",
    "    xtpl = eval_translate_kin_en(xtext)\n",
    "    xinputs = tokenizer(xtpl , return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**xinputs, max_new_tokens = 500, use_cache = True)\n",
    "    q1 = tokenizer.batch_decode(outputs)[0]\n",
    "    #extract the part \n",
    "    q2 = q1.split('assistant\\n')[1].split('<|im_end|>')[0]\n",
    "    return q2 \n",
    "\n",
    "\n",
    "def trans_en_kin(xtext):\n",
    "    '''\n",
    "    translate from english to Kinyarwanda \n",
    "    '''\n",
    "    \n",
    "    #apply template \n",
    "    xtpl = eval_translate_en_kin(xtext)\n",
    "    xinputs = tokenizer(xtpl , return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**xinputs, max_new_tokens = 500, use_cache = True)\n",
    "    q1 = tokenizer.batch_decode(outputs)[0]\n",
    "    #extract the part \n",
    "    q2 = q1.split('assistant\\n')[1].split('<|im_end|>')[0]\n",
    "    return q2 \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd241787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Israel yasabye abahungiye mu Majyepfo ya Gaza kongera guhungira aho bavuye\n",
      "text english: Israel has asked refugees in Southern Gaza to return to their homes\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Bugarama: Inkomoko y’umuco wo gushyingura umuntu babyina\n",
      "text english: Bugarama: The origin of the culture of burying a person dancing\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Perezida Biden yitiranyije u Bufaransa n’u Butaliyani\n",
      "text english: Biden confused France with Italy\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Ishyaka ritavuga rumwe na Perezida Macron ryatsinze icyiciro cya mbere cy’amatora y’abadepite\n",
      "text english: The party opposed to President Macron won the first round of the parliamentary elections\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Museveni yabwiye urubyiruko imyaka myiza yo gukora imibonano mpuzabitsina\n",
      "text english: Museveni told the youth the good age for having sex\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Ibibazo bitanu wibaza ku modoka zikoresha amashanyarazi mu Rwanda, n’ibisubizo byabyo\n",
      "text english: Five Questions about Electric Cars in Rwanda, and their Answers\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Ese Iran ishobora gufasha Hezbollah mu ntambara na Israel?\n",
      "text english: Can Iran help Hezbollah in the war with Israel?\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Hagaragajwe uruhare rw’abajyanama b’ubuzima mu kurwanya indwara z’ibyorezo\n",
      "text english: The role of health advisors in preventing pandemic diseases has been highlighted\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text kinyarwanda: Euro 2024: Espagne yandagaje Georgie isanga u Budage muri ¼\n",
      "text english: Euro 2024: Spain humiliates Georgia finds Germany in ¼\n",
      "-----\n",
      "text kinyarwanda: Perezida Kagame na Motsepe wa CAF batashye Stade Amahoro nshya\n",
      "text english: Perezida Kagame and Motsepe of CAF open the new Amahoro Stadium\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "## texts are taken from the headlines of https://igihe.com/index.php\n",
    "## on 2 July 2024 \n",
    "\n",
    "\n",
    "\n",
    "xtexts = ['Israel yasabye abahungiye mu Majyepfo ya Gaza kongera guhungira aho bavuye',\n",
    "         'Bugarama: Inkomoko y’umuco wo gushyingura umuntu babyina',\n",
    "         'Perezida Biden yitiranyije u Bufaransa n’u Butaliyani',\n",
    "         'Ishyaka ritavuga rumwe na Perezida Macron ryatsinze icyiciro cya mbere cy’amatora y’abadepite',\n",
    "         'Museveni yabwiye urubyiruko imyaka myiza yo gukora imibonano mpuzabitsina',\n",
    "         'Ibibazo bitanu wibaza ku modoka zikoresha amashanyarazi mu Rwanda, n’ibisubizo byabyo',\n",
    "          'Ese Iran ishobora gufasha Hezbollah mu ntambara na Israel?',\n",
    "          'Hagaragajwe uruhare rw’abajyanama b’ubuzima mu kurwanya indwara z’ibyorezo',\n",
    "          'Euro 2024: Espagne yandagaje Georgie isanga u Budage muri ¼',\n",
    "          'Perezida Kagame na Motsepe wa CAF batashye Stade Amahoro nshya'\n",
    "         ]\n",
    "\n",
    "for xtext in xtexts :\n",
    "    x = trans_kin_en(xtext)\n",
    "    print('text kinyarwanda:', xtext)\n",
    "    print('text english:',  x)    \n",
    "    print('-----')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601906d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "887ee057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Marine Le Pen says National Rally should not try to form government without a majority\n",
      "text Kinyarwanda: Marine Le Pen says National Rally should not try to form government without a majority\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Far-right politician says National Rally ‘wish to govern’ France but cannot do so properly without a majority\n",
      "text Kinyarwanda: Un politicien de droite dit au National Rally 'une volonté de gouverner la France sans pouvoir le faire correctement sans une majorité\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Portugal and Ronaldo save face as Costa’s shootout heroics sink Slovenia\n",
      "text Kinyarwanda: Portugal and Ronaldo save face as Costa’s shootout heroics sink Slovenia\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Greece introduces ‘growth-oriented’ six-day working week\n",
      "text Kinyarwanda: Greece yashyizeho icyumweru cyimyaka itandatu cyakazi\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Biden denounces supreme court decision on Trump immunity: ‘He’ll be more emboldened’\n",
      "text Kinyarwanda: Biden denounces supreme court decision on Trump immunity: ‘He’ll be more emboldened’\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: At least 39 killed in Kenya’s anti-tax protests, says rights watchdog\n",
      "text Kinyarwanda: At least 39 killed in Kenyas anti-tax protests, says rights watchdog\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Girmay first black African to win Tour de France stage\n",
      "text Kinyarwanda: Girmay first black African to win Tour de France stage\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: Suspected female suicide bombers death toll rises to 32 in Nigeria\n",
      "text Kinyarwanda: The death toll from a suspected female suicide bomber in Nigeria rises to 32\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text english: The Moroccan man sentenced to death for fighting for Ukraine\n",
      "text Kinyarwanda: The Moroccan man sentenced to death for fighting for Ukraine\n",
      "-----\n",
      "text english: Zelensky sacks top general accused of incompetence\n",
      "text Kinyarwanda: Zelensky dismisses the top general accused of incompetence\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "##  headlines from the Guardian and BBC on 2 July 2024 \n",
    "\n",
    "\n",
    "xtexts = ['Marine Le Pen says National Rally should not try to form government without a majority',\n",
    "          'Far-right politician says National Rally ‘wish to govern’ France but cannot do so properly without a majority',\n",
    "          'Portugal and Ronaldo save face as Costa’s shootout heroics sink Slovenia',\n",
    "          'Greece introduces ‘growth-oriented’ six-day working week',\n",
    "          'Biden denounces supreme court decision on Trump immunity: ‘He’ll be more emboldened’',\n",
    "          'At least 39 killed in Kenya’s anti-tax protests, says rights watchdog',\n",
    "          'Girmay first black African to win Tour de France stage',\n",
    "          'Suspected female suicide bombers death toll rises to 32 in Nigeria',\n",
    "          'The Moroccan man sentenced to death for fighting for Ukraine',\n",
    "         'Zelensky sacks top general accused of incompetence']\n",
    "          \n",
    "\n",
    "\n",
    "for xtext in xtexts :\n",
    "    x = trans_en_kin(xtext)\n",
    "    print('text english:', xtext)\n",
    "    print('text Kinyarwanda:',  x)    \n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7323df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa75914b",
   "metadata": {},
   "source": [
    "## save model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "979bd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"llamarwanda_rw_v1\") # Local saving\n",
    "#tokenizer.save_pretrained(\"llamarwanda_rw_v1\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6aefc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xLLM_unsloth)",
   "language": "python",
   "name": "xllm_unsloth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
